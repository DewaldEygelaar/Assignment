Building DAG of jobs...
Provided cores: 2
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	2	metrics
	3

rule metrics:
    input: sorted_reads/combined_HyperPrep.bam
    output: metrics/combined_HyperPrep.csv
    jobid: 7
    wildcards: sample=HyperPrep

rule metrics:
    input: sorted_reads/combined_HyperPlus.bam
    output: metrics/combined_HyperPlus.csv
    jobid: 1
    wildcards: sample=HyperPlus

Waiting at most 5 seconds for missing files.
Error in rule metrics:
    jobid: 7
    output: metrics/combined_HyperPrep.csv

RuleException:
CalledProcessError in line 85 of /home/dewald/Documents/snakemake/Snakefile:
Command ' set -euo pipefail;  /usr/bin/python3 /home/dewald/Documents/snakemake/scripts/.snakemake.0lhbwhmx.metrics.py ' returned non-zero exit status 1.
  File "/home/dewald/Documents/snakemake/Snakefile", line 85, in __rule_metrics
  File "/usr/lib/python3.6/concurrent/futures/thread.py", line 56, in run
Will exit after finishing currently running jobs.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2021-03-16T220936.164451.snakemake.log
